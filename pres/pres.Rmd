---
title: Contentious Data Structures 
subtitle: Leveraging Immutability for Parallelism 
author: Sean Laguna
date: Oct 20, 2016
output:
  beamer_presentation:
    slide_level: 3
    latex_engine: "xelatex"
    pandoc_args: [
        "--latex-engine-opt", "-shell-escape"
    ]
    includes:
      in_header: config.tex
    md_extensions: +raw_tex
---

# Intro


### Motivation 

- many programs not trivially parallelizable, but also not terribly complicated 
- most tools either not accommodating too bare-metal
- solutions (Clojure, Erlang, Chapel) too committal or invasive


### Observations on Easing Concurrency

- understanding the relevant/slated operations helps
- data layout shadows algorithm via access pattern
- records help mediate between function and state, but incur cost, which quickly becomes prohibitive


### Requirements for a Method

- less boilerplate than synchronization primitives
    - no learning a new series of pitfalls
- more flexible than "big data"-style solutions
    - handles data contention (in particular, races)
- efficient to the point of benefit
    - speedup over serial implementation on a 2-core machine? 


### Pinpointing the Task

In:

- description of stepwise or iterative task(s), algebraic properties of them
- data on which to operate, in a provided container
- number of desired threads 

Out:

- concurrent execution of task(s) on that many threads 


### Needs of Scientific Programs

- handle large amounts of data with computational interdependence; scaling 
- runtime options to match users needs; expressiveness
- small methodological changes should not require big design changes or manifest verification difficulties
- hardware multiplicity: distributed, manycore, gpu

# Supporting Material


### (Functionally) Persistent Data Structures

- not storage persistence, but uncanny similarities
- Okazaki, Hickey 
- data structures don't have to be immutable to look immutable


### Bit-partitioned Tries

\footnotesize

- underlying structure that provides effect 
- yields a vector or "hash map" depending on indexing scheme
- branching factor (elements/node) of 2... in practice, $2^5$, $2^6$, $2^{10}$

\begin{figure}[!h]
\centering
    \includegraphics[width=0.62\textwidth]{./img/clojure_triedef.png}
    \caption{Definition of parts of bit-partitioned trie. From \url{http://hypirion.com/musings/understanding-persistent-vector-pt-1}}
\end{figure}


###

\begin{figure}[!h]
\centering
    \includegraphics[width=0.85\textwidth]{./img/clojure_trielook.png}
    \caption{Using the bit-partitioned trie as a vector. From \url{http://hypirion.com/musings/understanding-persistent-vector-pt-2}}
\end{figure}


### Persistent and Transient Vectors

- persistence: always perform path-copying
- transience: perform path-copying whenever a node's ID differs from the root's ID


### Persistent Vector {.fragile}

\begin{center}
\begin{tikzpicture}[->, >=stealth',
                    level/.style = {
                        sibling distance = 2cm/#1,
                        level distance = 1.5cm},
                    transform shape]

    \node [name=t1, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
        child {
            node [name=t1cL, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
                child { node [name=bpv1clcl, treenode, fill=proc1] {1 \nodepart{two} 2} }
                child { node [treenode, fill=proc1] {3 \nodepart{two} 4} }
        }
        child {
            node [treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
                child { node [name=t1cRcL, treenode, fill=proc1] {5 \nodepart{two} 6} }
                child { node [treenode, fill=proc1] {7 \nodepart{two} \_} }
        };
    \node [name=t2, treenode, right=2cm of t1, fill=proc2,
           label={\small \texttt{i=na, Op(push\_back,8)}}] {$\ast$ \nodepart{two} $\ast$}
        child { node [draw=none] {} edge from parent[draw=none] }
        child {
            node [name=t2cR, treenode, fill=proc2] {$\ast$ \nodepart{two} $\ast$}
                child { node [draw=none] {} edge from parent[draw=none] }
                child { node [treenode, fill=proc2] {7 \nodepart{two} 8} }
        };
    \draw [-] (t2.two south) edge[out=240,in=60,dashed,->] (t1cL.north);
    \draw [-] (t2cR.one south) edge[out=240,in=60,dashed,->] (t1cRcL.north);
\end{tikzpicture}
\end{center}


### ...cont'd {.fragile}

\begin{center}
\begin{tikzpicture}[->, >=stealth',
                    level/.style = {
                        sibling distance = 4cm/#1,
                        level distance = 1.5cm },
                    transform shape]

    \node [name=t1, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
        child [sibling distance=2cm] { node [treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
            child [sibling distance=1cm] { node [name=bpv1clcl, treenode, fill=proc1] { 1 \nodepart{two} 2} }
            child [sibling distance=1cm] { node [treenode, fill=proc1] { 3 \nodepart{two} 4 } }
        }
        child [sibling distance=2cm] { node [treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
            child [sibling distance=1cm] { node [treenode, fill=proc1] { 5 \nodepart{two} 6 } }
            child [sibling distance=1cm] { node [treenode, fill=proc1] { 7 \nodepart{two} 8 } }
        };

    \node [name=t2, treenode, above right=0.6875cm and 2cm of t1, fill=proc2,
           label={\small \texttt{i=na, Op(push\_back,9)}}] {$\ast$ \nodepart{two} $\ast$}
        child { node [draw=none] {} edge from parent[draw=none] }
        child { node [treenode, fill=proc2] {$\ast$ \nodepart{two} \_ }
            child { node [treenode, fill=proc2] {$\ast$ \nodepart{two} \_ }
                child [sibling distance=1cm] { node [treenode, fill=proc2] { 9 \nodepart{two} \_ } }
                child { node [draw=none] {} edge from parent[draw=none] }
            }
            child { node [draw=none] {} edge from parent[draw=none] }
        };
    \draw [-] (t2.one south) edge[out=240,in=60,dashed,->] (t1.north);
\end{tikzpicture}
\end{center}


### Persistent Set {.fragile}

\begin{center}
\begin{tikzpicture}[->, >=stealth',
                    level/.style = {
                        sibling distance = 2cm/#1,
                        level distance = 1.5cm},
                    transform shape]

    \node [name=bpv1, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
        child {
            node [treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
                child { node [name=bpv1clcl, treenode, fill=proc1] {1 \nodepart{two} 2} }
                child { node [treenode, fill=proc1] {3 \nodepart{two} 4} }
        }
        child {
            node [name=bpv1cr, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
                child { node [treenode, fill=proc1] {5 \nodepart{two} 6} }
                child { node [treenode, fill=proc1] {7 \nodepart{two} \_} }
        };

        \node [name=bpv2, treenode, right=4cm of bpv1, fill=proc2,
                label={\small \texttt{i=3, Op(+,1)}}] {$\ast$ \nodepart{two} $\ast$}
        child {
            node [name=bpv2cl, treenode, fill=proc2] {$\ast$ \nodepart{two} $\ast$}
                child { node [draw=none] {} edge from parent[draw=none] }
                child {
                    node [treenode, fill=proc2] {3 \nodepart{two} 5}
                }
        }
        child { node [draw=none] {} edge from parent[draw=none] };

        \node [name=bpv3, treenode, right=2cm of bpv2, fill=proc3,
                label={\small \texttt{i=3, Op(+,2)}}] {$\ast$ \nodepart{two} $\ast$}
        child {
            node [name=bpv3cl, treenode, fill=proc3] {$\ast$ \nodepart{two} $\ast$}
                child { node [draw=none] {} edge from parent[draw=none] }
                child {
                    node [treenode, fill=proc3] {3 \nodepart{two} 6}
                }
        }
        child { node [draw=none] {} edge from parent[draw=none] };

    \draw [-] (bpv2.two south) edge[out=240,in=60,dashed,->] (bpv1cr.north);
    \draw [-] (bpv3.two south) edge[out=240,in=60,dashed,->] (bpv1cr.north);
    \draw [-] (bpv2cl.one south) edge[out=240,in=60,dashed,->] (bpv1clcl.north);
    \draw [-] (bpv3cl.one south) edge[out=240,in=60,dashed,->] (bpv1clcl.north);
    %\draw [-latex] (test2.one south) -- (test3.one north);

\end{tikzpicture}
\end{center}


### Transient Set {.fragile}

\begin{center}
\begin{tikzpicture}[->, >=stealth',
                    level/.style = {
                        sibling distance = 2cm/#1,
                        level distance = 1.5cm},
                    transform shape]

    \node [name=bpv1, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
        child { node [treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
            child { node [name=bpv1clcl, treenode, fill=proc1] {1 \nodepart{two} 2} }
            child { node [treenode, fill=proc1] {3 \nodepart{two} 4} }
        }
        child { node [name=bpv1cr, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
            child { node [treenode, fill=proc1] {5 \nodepart{two} 6} }
            child { node [treenode, fill=proc1] {7 \nodepart{two} \_} }
        };

    \node [name=bpv2, treenode, right=4cm of bpv1, fill=proc2,
           label={\small \texttt{i=3, Op(+,1)}}] {$\ast$ \nodepart{two} $\ast$}
        child { node [name=bpv2cl, treenode, fill=proc2] {$\ast$ \nodepart{two} $\ast$}
            child { node [draw=none] {} edge from parent[draw=none] }
            child { node [treenode, fill=proc2] {3 \nodepart{two} 5} }
        }
        child { node [draw=none] {} edge from parent[draw=none] };

    
    \draw [-] (bpv2.two south) edge[out=240,in=60,dashed,->] (bpv1cr.north);
    \draw [-] (bpv2cl.one south) edge[out=240,in=60,dashed,->] (bpv1clcl.north);
    %\draw [-latex] (test2.one south) -- (test3.one north);

\end{tikzpicture}
\end{center}


### ...cont'd {.fragile}

\begin{center}
\begin{tikzpicture}[->, >=stealth',
                    level/.style = {
                        sibling distance = 2cm/#1,
                        level distance = 1.5cm},
                    transform shape]

    \node [name=bpv1, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
        child { node [treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
            child { node [name=bpv1clcl, treenode, fill=proc1] {1 \nodepart{two} 2} }
            child { node [treenode, fill=proc1] {3 \nodepart{two} 4} }
        }
        child { node [name=bpv1cr, treenode, fill=proc1] {$\ast$ \nodepart{two} $\ast$}
            child { node [treenode, fill=proc1] {5 \nodepart{two} 6} }
            child { node [treenode, fill=proc1] {7 \nodepart{two} \_} }
        };

    \node [name=bpv2, treenode, right=4cm of bpv1, fill=proc2,
           label={\small \texttt{i=2, Op(+,1)}}] {$\ast$ \nodepart{two} $\ast$}
        child { node [name=bpv2cl, treenode, fill=proc2] {$\ast$ \nodepart{two} $\ast$}
            child { node [draw=none] {} edge from parent[draw=none] }
            child { node [treenode, fill=proc2] {4 \nodepart{two} 5} }
        }
        child { node [draw=none] {} edge from parent[draw=none] };

    
    \draw [-] (bpv2.two south) edge[out=240,in=60,dashed,->] (bpv1cr.north);
    \draw [-] (bpv2cl.one south) edge[out=240,in=60,dashed,->] (bpv1clcl.north);
    %\draw [-latex] (test2.one south) -- (test3.one north);

\end{tikzpicture}
\end{center}


### Dependency Graphs

Identify...

- opportunities for parallelism
- points that necessitate concurrency control 

### Cases

1. All edges $e \in E(P)$ incident to $n$ are \textbf{incoming} to $n$, and

    all edges $e \in E(Q)$ indicent to $n$ are \textbf{outgoing} from $n$:

    - $n$ connects $P$ to $Q$, and $Q$ can only be computed once $P$ has been.
2. All edges $e \in E(P)$ incident to $n$ are \textbf{incoming} to $n$, and
  
    all edges $e \in E(Q)$ indicent to $n$ are \textbf{incoming} to $n$:
    
    - $P$ and $Q$ can be computed in parallel, but the value of $n$ can only be
    determineded once both $P$ and $Q$ have been computed.
3. All edges $e \in E(P)$ incident to $n$ are \textbf{outgoing} from $n$, and
  
    all edges $e \in E(Q)$ indicent to $n$ are \textbf{outgoing} from $n$:
    
    - $P$ and $Q$ can be computed in parallel, but only once the value of $n$ has
    been determined.


### Atomic Operations 

- lock-free MPMC work queue
    - for managing tasks among threads
- IDs for versioning container 
- managing the interrelationships (much more later) 


### Recap: Three "Views" of The Method 

1. theoreric (dependency graph and algebra) 
2. memory-based (data layout and transformation) 
3. operative (implementation and execution) 


### Related Efforts

- Clojure, leveraging persistence
    - reducers/transducers, etc
- concurrent data structures
    - CITRUS/CASTLE trees
    - cuckoo hashing
    - PRCU, RLU (read-copy-update successors)
- transactional memory
    - notably the identification and accommodation of pathological execution ordering


# Methods and Implementation

### Overview

- each thread gets an ID and its own snapshot of the data structure at each step
- each thread will perform its work with that snapshot as if the values were correct 
- conflict detection and resolution will propagate any late updates, using knowledge of the partition and operations at hand to finalize all values 

Remember... Persistent updates create new copies of the vector.
So, they will look immutable, and return the head of the modified vector.
Transient updates will change the copy directly if the path to that leaf has already been modified via that copy


### Contentious Vector

transient vector with extra stuff for parallel operation

- a `tracker` to keep track of
    - global snapshot
    - partition
    - operator (actual operator, "outer inverse", identity)
    - index mapping (and list of "contended" indices)
    - any frozen auxiliary `ctvector`s
    - any [corresponding] splinters
    - latches to count down reattachment
- global and thread-local snapshot management
    - `freeze`, `detach` & `reattach` methods
    - fast `assign` of range of values from one `ctvector` to another
- conflict detection and resolution methods


### Contentious Namespace

some extra stuff

- a threadpool for ordering concurrent but stepwise "tasks"
    - no synchronization between steps, but can force resolution via `finish`
    - producer-consumer queues for tasks and resolutions
- basic instances of:
    - partition functions
    - index mappings
    - operators


### Credit to Facebook's Folly Library

Facebook's Folly library provides:

  - `ProducerConsumerQueue`: threadpool
  - `LifoSem`: threadpool
  - `AtomicHashMap`: trackers, latches, splinters
  - marginal performance benefits in the form of consistency


### Freeze

- take a persistent "global snapshot" of the vector 
- take a persistent "local snapshot" of the vector for each thread
- take a transient copy ("splinter") of each local snapshot for computing
    - they "hang off" the local snapshot
    - so do auxiliary contentious vectors that contribute to the computed values


### From `*this` to `dep` {.fragile}

```C++
auto dep_key = reinterpret_cast<uintptr_t>(&dep);
// we want our output to depend on input
this->tracker.emplace(dep_key, imap, op);
dep.latches.emplace(dep_key, new boost::latch(ctts::HWCONC));
{
    // locked this->_data
    std::lock_guard<std::mutex> lock(dlck);
    this->_snap = this->_data;
    this->_data = this->_data.new_id();
}
```


### Detach

- create a splinter for a processor to compute with
- separate interface:
    - can only perform registered operation
    - can only access/modify specified domain and range for that operation


### {.fragile}


```C++
auto &dep_tracker = this->tracker.find(dkey);
// must use _orig if not monotonic
{
    // locked this->_data, because each proc 0 <= p < P runs this
    std::lock_guard<std::mutex> lock(dlck);
    dep_tracker._used[p] = this->_data;
    this->_data = this->_data.new_id();
}
splinter<T> splt(dep_tracker, p);
dep.splinters.emplace(splt._data.get_id());
return splt;
```

### Reattach

- for all disjunctly-modified leaves, perform most-common-branch assignment
- for non-disjunctly modified leaves, copy disjunctly-modified values
    - pray the other values will be fine


### Conflict Detection and Resolution

- for every potentially contended value, the conflict detection function is run
- if a conflict is detected, the resolution function is run
    - normally, this involves recovering the difference using the inverse of the "outer operator", and then using the original operator again upon the fresh value and this difference
    - other possibilities exist too, under special circumstances


###

```C++
for (size_t ci : dep_tracker.contended) {
    for (size_t cimap : dep_tracker.imap(ci)) {
        T cmap& = dep._data[cimap];
        // use iterators to get const references; faster
        auto curr = this->_data.cbegin() + ci;
        auto trck = dep_tracker._used[p].cbegin() + ci;
        T diff = dep_op.inv(*curr, *trck);
        if (diff != dep_op.identity) {
            cmap = dep_op.f(cmap, diff);
            // since this changed,
            // we may need to resolve it in the future, too
            dep.maybe_contended.insert(cimap);
        }
    }
}
```


# Practical Usage

### User Interface

```C++
// creation
ctvector<double> cont_inp;
for (size_t i = 0; i < n; ++i) {
    cont_inp.unprotected_push_back(rand());
}

// reduce
auto cont_ret = cont_inp.reduce(ctts::plus<double>);
ctts::tp.finish();

// foreach
auto ret1 = cont_inp.foreach(ctts::mult<double>, 2);
auto ret2 = ret1->foreach(ctts::mult<double>, cont_other);
ctts::tp.finish();
```


###

```C++
// stencil
for (int t = 1; t < r; ++t) {
    int icurr = t % t_store;
    int iprev = (t-1) % t_store;
    grid[icurr] = grid[iprev]->stencil<-1, 0, 1>(
                                      {1.0*s, -2.0*s, 1.0*s});
    if (t % (t_store-1) == (t_store-2)) {
        ctts::tp.finish();
    }
}
ctts::tp.finish();
```


### Detail - `reduce`

```C++
ctvector<T> ctvector<T>::reduce(const ctts::op<T> op)
{
    // our reduce dep is just one value
    auto dep = ctvector<T>();
    dep.unprotected_push_back(op.identity);

    freeze(dep, ctts::alltoone<0>, op);
    // no template parameters because no auxiliary variables
    exec_par<>(ctts::reduce_splt<T>, dep);

    return dep;
}
```


### Detail - `foreach`

```C++
std::shared_ptr<ctvector<T>> ctvector<T>::foreach(
                                        const ctts::op<T> op,
                                        const T &val)
{
    auto dep = std::make_shared<ctvector<T>>(*this);

    // template parameter is the arg to the foreach op
    freeze(*dep, ctts::identity, op);
    exec_par<T>(ctts::foreach_splt<T>, *dep, val);

    return dep;
}
```

It would be really nice to get type inference on the template parameters.

### Thread-level View of `foreach`

```C++
void foreach_splt(ctvector<T> &cont, ctvector<T> &dep,
                  const uint16_t p, const T &val)
{
    size_t a, b;
    std::tie(a, b) = partition(p, cont.size());
    splinter<T> splt = cont.detach(dep, p);
    const binary_fp<T> fp = splt.ops[0].f;
    auto end = splt._data.begin() + b;
    for (auto it = splt._data.begin() + a; it != end; ++it) {
        *it = fp(*it, val);
    }
    cont.reattach(splt, dep, p, a, b);
}
```


### Detail - `stencil`

\scriptsize

```C++
template <typename T>
template <int... Offs>
std::shared_ptr<ctvector<T>> ctvector<T>::stencil(const std::vector<T> &coeffs)
{
    constexpr size_t NS = sizeof...(Offs);
    std::array<ctts::imap_fp, NS> offs{ {ctts::offset<Offs>...} };

    auto dep = std::make_shared<ctvector<T>>(*this);
    freeze(*dep, ctts::identity, ctts::plus_fp<T>);
    for (size_t i = 0; i < NS; ++i) {
        ctts::op<T> fullop = {
            0,
            boost::bind<T>(ctts::multplus_fp<T>, _1, _2, coeffs[i]),
            ctts::minus_fp<T>  // the "inverse" is that of the "outer operator"
        };
        freeze(*this, *dep, offs[i], fullop);
    }
    for (uint16_t p = 0; p < ctts::HWCONC; ++p) {
        auto task = std::bind(ctts::stencil_splt<T, NS>, std::ref(*this), std::ref(*dep), p);
        ctts::tp.submit(task, p);
    }
    return dep;
}
```


### Thread-level View of `stencil`

\footnotesize

```C++
template <typename T, size_t NS>
void stencil_splt(ctvector<T> &cont, ctvector<T> &dep, const uint16_t p)
{
    // get bounds (a, b) and "safe" bounds (ap, bp) for stencil (tedious)
    for (size_t i = 0; i < NS; ++i) {
        os[i] = a - imaps[i+1](a);
        ioffs[i] = os[i] - os[0];
        fs[i] = tracker.ops[i+1].f;
    }
    splinter<T> splt = cont.detach(dep, p);
    auto trck = tracker._used[p].cbegin() + (ap+os[0]);
    auto end = splt._data.begin() + bp;
    for (auto it = splt._data.begin() + ap; it != end; ++it, ++trck) {
        T &target = *it;
        for (size_t i = 0; i < NS; ++i) {
            target = fs[i](target, *(trck + ioffs[i]));
        }
    }
    cont.reattach(splt, dep, p, a, b);
}
```


# Closer Look: Stencils


### 1D Heat Equation

Heat Equation
\vspace{-2em}
\begin{align*}
    \frac{\partial u}{\partial t} - \alpha \nabla^2 u &= 0, \text{ or} \\
    \frac{\partial u}{\partial t} - \alpha \frac{\partial^2 u}{\partial x^2} &= 0
\end{align*}

4-point finite difference stencil
\vspace{-2em}
\begin{align*}
    u^{t+1}_x &= a(u^{t}_{x+1} + u^{t}_{x-1}) + b(u^{t}_{x}), \\
    a &= r \text{ and } b = (1-2r) \text{ for } r = \kappa / h^2 
\end{align*}


### Data Dependencies

Processor $p$ has a chunk of of the domain with values 
\vspace{-2em}
\begin{align*}
    x_p     &= \{\alpha*p, \alpha*(p+1)-1\} \text{, where} \\
    \alpha  &= X / P 
\end{align*}

$p$ can compute:
\vspace{-2em}
\begin{align*}
    u^{t+1}_{x_{t1}} \text{ for } x_{t1} &\in \{ \alpha*p + 1, \dots \alpha*(p+1)-2 \} \text{,} \\
    u^{t+2}_{x_{t2}} \text{ for } x_{t2} &\in \{ \alpha*p + 2, \dots \alpha*(p+1)-3 \} \text{,} \\
    ... \\
    u^{t+p}_{x_{t\alpha}} \text{ for } x_{t\alpha} &\in \emptyset
\end{align*}

with no communiation.


### ...cont'd

After $\alpha$ steps through time, processor $p$ must wait for processor $p-1$ to
finish computing its data. Likewise, waiting indefinitely for both processor
$p-1$ and $p+1$ to complete only allows for $\alpha / 2$ steps through time to be
completed. Thus, we can say that
\vspace{-2em}
\begin{align*}
    u^{t + i}_{\alpha*p + i-1} &\text{ depends on } p-1 \text{, and} \\
    u^{t + i}_{\alpha*(p+1)-1 - (i-1)} &\text{ depends on } p+1 \text{,} \\
                                       &\text{for } i \in \{ 1, \alpha \} \text{.}
\end{align*}


# Results


### Tests

Reduce: reduction of values using multiplication as the operator  

- vs `seq`, `vec`, `async`, `omp`

Foreach: data-parallel aggregate operation using addition

- vs serial implementation

Heat: 1D spatial finite difference solver for heat equation

- vs serial implementation


### `reduce` - runtime at various problem sizes

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/reduce+foreach-linux/reduce_size-v-time.png}
\end{figure}


### `reduce` - speedup for "small" problem size

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/reduce+foreach-linux/reduce_procs-v-speed-s.png}
\end{figure}


### `reduce` - speedup for "medium" problem size

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/reduce+foreach-linux/reduce_procs-v-speed-m.png}
\end{figure}


### `reduce` - speedup for "large" problem size


\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/reduce+foreach-linux/reduce_procs-v-speed-l.png}
\end{figure}


### `reduce` - speedup summary

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/reduce+foreach-linux/reduce_procs-v-speed-a.png}
\end{figure}


### `foreach` - runtime at various problem sizes

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/reduce+foreach-linux/foreach_size-v-time.png}
\end{figure}


### `foreach` - speedup summary

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/reduce+foreach-linux/foreach_procs-v-speed-a.png}
\end{figure}


### `heat` - runtime at various spatial sizes

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/heat-linux/heat_size-v-time.png}
\end{figure}


### `heat` - speedup summary for spatial domain size variation

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/heat-linux/heat_width-v-speed-a.png}
\end{figure}


### `heat` - speedup summary for time domain size variation

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{../Figures/heat-linux/heat_steps-v-speed-a.png}
\end{figure}


# Observations


### General Outcome

- small problem sizes don't fare well
    - perhaps tolerable
    - not easy to parallelize along time domain
- large number of timesteps doesn't make things worse
    - you can always cap the unresolved depth, anyway

### Poor Performance?

- dissatisfying performance across the board
    - shared memory is dissatisfying, caching is dissatisfying
    - OpenMP is a bit less dissatisfying
- even SSE/AVX instructions perform similarly
- `std::vector` struggles as its size increases
    - contiguous memory means large allocations


# Where to Go From Here


### Improvements

- API could use some polish
    - be stricter about correctness for splinters
    - copying problem
    - incorporate vector size changes into tracking system, or as operations
- performance leads
    - memory arenas: reuse leaves to avoid redundant work
    - branching factor: tuned, heterogeneous
    - different trie indexing scheme: gather contended values
    - computation ordering: minimize potential conflicts


### Partitioning

- fundamental problem has been "reduced" to partitioning and managing the index sets for each processor, and the mapping between them
    - data dependencies affect the optimal partition
    - provides a framework for tackling this problem
  

# Thank you!

\begin{comment}
\emph{Induction Principle}: The formula $\phi$ may be derived by proving the formula \medskip

\begin{itemize}[label=$\lozenge$, itemsep=2ex]

\item \emph{Base Case}: $P=0$. Consider that this corresponds to serial code. Thus, there will be no contention.

$P=1$.
There are two orderings: $p$ writes $d_q$ before $q$ reads it, and $q$ reads $d_q$ before $p$ writes it.
In the former case, the race is avoided as the code takes the ordering that would normally occur under serial, single-thread conditions.
In the latter case, when $q$ runs $C$ on $d_q$, it will detect a conflict, and run its resolution function $R$ on $d_q$, producting the correct value.

$P=2$.
The value $d_q$ will now be written by both $r$ and $s$ at the same logical time.(Note it is possible that, e.g., $r=q$, or that in the former case, $p=q$).
If one updates and then the other does, the updates may fall prey to the same contention problems normally observed sans synchronization.
But, recall that performing the resolution is itself an update and thus will be treated persistently.
Therefore, each processor will:
\begin{itemize}[label=$\cdot$,itemsep=2ex]
\item create its own version of the CT vector it must resolve;
\item inform the other about the new value it produced for $d_q$;
\item carry out conflict detection;
\end{itemize}

and, at least one will detect a conflict, namely, the one whose reference was freshened before it ran its $C$. }

\item \emph{Corollary}: Either $r$ must freshen before $s$ runs its $C$ or vice versa.

\item \emph{Proof}:
Assume $r$ does not freshen before $s$ runs its $C$, call that $C_s$.
Consider a logical point in time before $r$ freshens but after $C_s$ runs.
As $r$ has not even freshened yet, $r$ has also not run its $C$, call that $C_r$.
But then, $C_s$ has been run, by assumption, and as $C_s$ runs after $s$ freshens, $s$ has freshened. 
Hence, $s$ has freshened before $C_r$ runs.
The proof holds without loss of generality as $r$ and $s$ are interchangable. 

Then, at least the one processor that detected a conflict will arrive at the correct value.
If both values freshen before both conflict detections take place, then both will detect a conflict.
The processor that happens to freshen last will have its version of $v$ used when procuring $d_q$, but both will have the correct values, making it unnecessary to ensure the use of one or the other.

\item \emph{Inductive Step}:
For each $1 \leq i \leq P$, say processor $p_i$ will write the value $d_q$ to be used by processor $q$. 
The resulting $d_q$ will be be

\item \texttt{(EO-ORDINALP} $m$\texttt{)}

\item For each $1 \leq i \leq k$ and for $1 \leq j \leq h_i$, 
\[\texttt{(IMPLIES } q_i \texttt{ (EO-ORD-< } m/\sigma_{i,j} \quad m \texttt{))}\]

\end{itemize}
\end{comment}

